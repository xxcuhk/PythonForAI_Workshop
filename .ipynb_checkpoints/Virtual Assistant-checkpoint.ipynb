{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funky-lancaster",
   "metadata": {},
   "source": [
    "<img src=\"https://ai4future.keep.edu.hk/wp-content/uploads/2020/02/CUHK_AI_Logo_Update_Web.png\" width=\"200\" align=\"right\"> <br><br><br><br>\n",
    "<h1><span style=\"color:#338DFF\"> AI With Python Workshop </span></h1>\n",
    "\n",
    "### Welcome to the AI with Python Workshop by CUHK-Jockey Club AI for the Future Project\n",
    "\n",
    "This notebook complements the powerpoint slides during the workshop and will be used to do the coding exercises \n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-butler",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# AI Project using Python\n",
    "\n",
    "In this project we will create a virtual assistant that understands natural language. We will be able to interact with it in English to perform the following tasks:\n",
    "\n",
    "<img src=\"https://cdn.dribbble.com/users/324481/screenshots/7149521/media/4fb25c016884dbbd1352e75916fa5f81.png?compress=1&resize=400x300\" width=\"200\" align=\"right\">\n",
    "\n",
    "* **Chit-chat**\n",
    "    * Tell jokes\n",
    "* **Weather**\n",
    "    * Get current weather for any city\n",
    "* **Movies**\n",
    "    * Get rating for a movie\n",
    "    * Find the director(s) of a movie\n",
    "    * Find the actor(s) in a movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-prerequisite",
   "metadata": {},
   "source": [
    "## Learning outcomes\n",
    "\n",
    "In this tutorial you will learn:  \n",
    "* The basic terminologies required in virtual assistant systems\n",
    "    * Intents\n",
    "    * Slots\n",
    "    * Entities\n",
    "    * Utterances\n",
    "* How to use SNIPS-NLU to understand natural language and detect intents, slots, and entities from utterances.\n",
    "* How to use the detected intents, slots and entities to get information from APIs\n",
    "----\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-auckland",
   "metadata": {},
   "source": [
    "# Let's Begin\n",
    "\n",
    "## Install the Libraries\n",
    "First we need to install the required libraries.  \n",
    "Go to Datalore's **Library Manager** on the left side and install the following libraries.\n",
    "\n",
    "* **snips-nlu**\n",
    "    * This library deals with the Natural Language Understanding to detect intents, slots, and entities.\n",
    "* **pyjokes**\n",
    "    * This library provides jokes based on Python.\n",
    "* **python-weather**\n",
    "    * This library provides the weather API to get weather information.\n",
    "* **imdbpy**\n",
    "    * This library provides the IMDB movie APU to get movie information.\n",
    "    \n",
    "Move on to the next step once all the libraries are successfully installed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-arrangement",
   "metadata": {},
   "source": [
    "## Prepare the training dataset\n",
    "\n",
    "Prepare the training dataset to train your Natural Language Understanding (NLU) Engine.\n",
    "\n",
    "In our training dataset, we will have the following **intents**:\n",
    "\n",
    "1. **tell_joke** : To detect that the user is asking the virtual assistant for a joke. There are no slots required for this intent.\n",
    "    * **Example utterances:** \"Hi, tell me a joke.\", \"I'm bored. Entertain me with a funny joke.\"  \n",
    "    \n",
    "    \n",
    "2. **get_weather** : To detect that the user is asking for current weather of a city. For this intent we need to fill a slot for ``city``.\n",
    "    * **Example utterances:** \"How is the weather in New York?\", \"I wonder how the weather conditions are like in Hong Kong right now?\"  \n",
    "    \n",
    "    \n",
    "    \n",
    "3. **get_rating** : To detect that the user is asking the rating for a movie. For this intent we need to fill a slot for ``movie_name``.\n",
    "    * **Example utterances:** \"How good is the movie Batman?\", \"I want to know the movie ratings for Fast and Furious\"  \n",
    "    \n",
    "    \n",
    "    \n",
    "4. **get_director** : To detect that the user is asking for who is the director of a movie. For this intent we need to fill a slot for ``movie_name``.\n",
    "    * **Example utterances:** \"Who directed Tenet?\", \"I want to know the director of the movie Ip Man\"  \n",
    "\n",
    "\n",
    "\n",
    "5. **get_actors** : To detect that the user is asking for who acted in a movie. For this intent we need to fill a slot for ``movie_name``.\n",
    "    * **Example utterances:** \"Who acted in the movie Joker?\", \"What is the cast for the movie The Boat People?\"\n",
    "    \n",
    "\n",
    "We will have the following **entities**:\n",
    "\n",
    "1. **city**\n",
    "    * **Examples**: Hong Kong, New York, Dublin, London  \n",
    "    \n",
    "    \n",
    "2. **movie_name**\n",
    "    * **Examples**: Star Wars, Ip Man, The Dark Knight, La la land\n",
    "\n",
    "\n",
    "**We have created a starter dataset for you with 1 example intent and 1 example entity in the file ``dataset.yaml``**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-baking",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Run the cell below to import the required libraries and functions.\n",
    "\n",
    "**Note:** _We have pre-written some code to simplify the weather and movie rating APIs in the file ``utils.py``. You can view the file later to understand the inner working in more detail._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "\n",
    "import io\n",
    "import json\n",
    "from snips_nlu import SnipsNLUEngine\n",
    "from snips_nlu.default_configs import CONFIG_EN\n",
    "!python -m snips_nlu download en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-observer",
   "metadata": {},
   "source": [
    "## Convert the dataset to json format\n",
    "\n",
    "Run the next cell to convert the dataset to json format to train the NLU Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "\n",
    "!snips-nlu generate-dataset en dataset.yaml > dataset.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-office",
   "metadata": {},
   "source": [
    "# Open the dataset\n",
    "\n",
    "To open the dataset, we will follow the following steps:\n",
    "1. Use ``open`` function to load the file into Python in a variable called ``dataset_file``.\n",
    "2. use ``load`` function from ``json`` as ``json.load(dataset_file)`` into a variable called ``training_dataset``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "dataset_file = open(\"dataset.json\", \"r\")\n",
    "training_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-violence",
   "metadata": {},
   "source": [
    "## Initialize the Snips-NLU Engine with English Configuration\n",
    "\n",
    "We will start our Snips-NLU engine using the ``SnipsNLUEngine()``. We will pass a parameter in it as ``config==CONFIG_EN``, which will load the English language configuration in our NLU engine. \n",
    "\n",
    "We will store the Snips-NLU engine in a variable called ``NLUengine``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "\n",
    "NLUengine = SnipsNLUEngine(config=CONFIG_EN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-trunk",
   "metadata": {},
   "source": [
    "## Try the engine to predict the slots and intents for an utterance\n",
    "\n",
    "We will use our NLU engine's ``parse`` function to make a prediction as ``prediction = NLUengine.parse(your utterance)``\n",
    "\n",
    "You will notice that it will give a ``Not Trained Error`` because we haven't trained the engine yet. In the next step, we will train the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "\n",
    "predictions = engine.parse(\"How's the weather in Hong Kong?\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-premium",
   "metadata": {},
   "source": [
    "## Train the NLU Engine\n",
    "\n",
    "We will now train the NLU engine using our training dataset. We will use ``fit()`` function to train the model\n",
    "\n",
    "To train the model we have to run:\n",
    "```\n",
    "NLUengine.fit(training_dataset)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "\n",
    "NLUengine.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-issue",
   "metadata": {},
   "source": [
    "## Let's try to predict again\n",
    "\n",
    "Let's try to use our model on the sentence ``\"How's the weather in Hong Kong\"``\n",
    "\n",
    "Use the function ``prediction = NLUengine.parse(your utterance)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "\n",
    "prediction = NLUengine.parse(\"How's the weather in Hong Kong?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-cameroon",
   "metadata": {},
   "source": [
    "## Print the prediction\n",
    "\n",
    "To print the prediction in a more readable format we will use ``json.dumps()`` function as:\n",
    "\n",
    "``print(json.dumps(prediction, indent=2))``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "\n",
    "print(json.dumps(prediction, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-method",
   "metadata": {},
   "source": [
    "## Get the intent\n",
    "\n",
    "To get the intent we access the intent name element from the resulted ``prediction`` dictionary.\n",
    "\n",
    "We have made a function for you to get the intent easily. You can use ``get_intent(prediction)`` to get the intent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "\n",
    "print(get_intent(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-active",
   "metadata": {},
   "source": [
    "## Get the slot's entity type\n",
    "There can be multiple slots mentioned in an utternace. But in our tutorial we only have 1 slot per utterance. \n",
    "\n",
    "You can use our function ``get_entity_type(prediction)`` to get the slot's entity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "\n",
    "print(get_entity_type(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-perry",
   "metadata": {},
   "source": [
    "## Get the entity's value\n",
    "\n",
    "Similar to slots, there can be multiple entity values. But our tutorial will only have 1 value per slot. \n",
    "\n",
    "You can use our function ``get_entity_value(prediction)`` to get the slot's value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "\n",
    "print(get_entity_value(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-stewart",
   "metadata": {},
   "source": [
    "## Integrate NLU Engine with API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_weather\n",
    "\n",
    "# declare the client. format defaults to metric system (celcius, km/h, etc.)\n",
    "client = python_weather.Client(format=python_weather.IMPERIAL)\n",
    "\n",
    "# fetch a weather forecast from a city\n",
    "weather = await client.find(\"Washington DC\")\n",
    "\n",
    "# returns the current city temperature (int)\n",
    "print(weather.current.temperature)\n",
    "\n",
    "# get the weather forecast for a few days\n",
    "for forecast in weather.forecast:\n",
    "    print(str(forecast.date), forecast.sky_text, forecast.temperature)\n",
    "\n",
    "# close the wrapper once done\n",
    "await client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb import IMDb\n",
    "\n",
    "# create an instance of the IMDb class\n",
    "ia = IMDb()\n",
    "\n",
    "# get a movie and print its director(s)\n",
    "movie = ia.search_movie(\"The Dark Knight\")\n",
    "the_matrix = ia.get_movie(movie[0].movieID)\n",
    "for director in the_matrix['directors']:\n",
    "    print(director['name'])\n",
    "\n",
    "# show all information that are currently available for a movie\n",
    "print(sorted(the_matrix.keys()))\n",
    "\n",
    "# show all information sets that can be fetched for a movie\n",
    "print(ia.get_movie_infoset())\n",
    "\n",
    "# update a Movie object with more information\n",
    "ia.update(the_matrix, ['technical'])\n",
    "# show which keys were added by the information set\n",
    "#print(the_matrix.infoset2keys['technical'])\n",
    "# print one of the new keys\n",
    "print(the_matrix.get('tech'))\n",
    "\n",
    "the_matrix['rating']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
